<!DOCTYPE html>
<html lang="zh-Hant">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>語音聊天機器人</title>
    <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
</head>
<body>
    <div class="container mt-5">
        <h1 class="mb-4">用 Raspberry Pi 4 + ollama + vosk + piper 實現語音聊天機器人</h1>
        <h2>1. 硬體需求:</h2>
        <ul>
            <li>Raspberry Pi 4 / 4GB</li>
            <li>usb 麥克風</li>
            <li>usb 供電，3.5mm音源輸入喇叭</li>
        </ul>
        <h2>2. 安裝大語言模型(LLM) ollama</h2>
        <ol>
            <li>安裝大語言模型 ollama
                <pre><code>curl -fsSL https://ollama.com/install.sh  | sh</code></pre>
            </li>
            <li>下載並執行 gemma:2b 模型
                <pre><code>ollama run gemma:2b</code></pre>
                如果有成功安裝，此時就可以跟模型對話了
            </li>
            <li>ollama list 可列出已經下載的 ollama 模型
                <pre><code>ollama list</code></pre>
                <pre><code>NAME               ID              SIZE      MODIFIED
gemma:2b           b50d6c999e59    1.7 GB    2 days ago
llama3.2:latest    a80c4f17acd5    2.0 GB    2 days ago
llama3.2:3b        a80c4f17acd5    2.0 GB    2 days ago</code></pre>
            </li>
        </ol>
        <h2>3. 安裝 python 語音辨識套件（ASR）- vosk</h2>
        <ol>
            <li>安裝 python 套件
                <pre><code>pip install vosk</code></pre>
            </li>
            <li>下載中文語言模型
                <pre><code>mkdir vosk_models
cd vosk_models
wget https://alphacephei.com/vosk/models/vosk-model-small-cn-0.22.zip</code></pre>
            </li>
            <li>解壓縮 vosk-model-small-cn-0.22.zip
                <pre><code>unzip vosk-model-small-cn-0.22.zip</code></pre>
            </li>
        </ol>
        <h2>4. 安裝 python 語音合成套件 - piper-tts</h2>
        <ol>
            <li>安裝 python 套件
                <pre><code>pip install piper-tts</code></pre>
            </li>
            <li>下載中文語音模型及其json
                <pre><code>mkdir piper_models
cd piper_models
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/zh/zh_CN/huayan/medium/zh_CN-huayan-medium.onnx
wget https://huggingface.co/rhasspy/piper-voices/resolve/main/zh/zh_CN/huayan/medium/zh_CN-huayan-medium.onnx.json</code></pre>
            </li>
            <li>測試 piper 是否正常
                <pre><code>piper --help</code></pre>
                Illegal instruction
                出現 Illegal instruction，因為最新版的 onnxruntime、numpy跟 Pi4 相衝突，要降版本
                <pre><code>pip list</code></pre>
                <pre><code>Package         Version
--------------- --------------
coloredlogs     15.0.1
flatbuffers     20181003210633
humanfriendly   10.0
mpmath          1.3.0
numpy           2.2.4
onnxruntime     1.21.0
packaging       24.2
pip             23.0.1
piper-phonemize 1.1.0
piper-tts       1.2.0
protobuf        6.30.1
setuptools      66.1.1
sympy           1.13.3</code></pre>
            </li>
            <li>將 onnxruntime、numpy 降版本
                <pre><code>pip uninstall onnxruntime -y
pip install onnxruntime==1.17.1
pip uninstall numpy -y
pip install numpy==1.24.4</code></pre>
            </li>
            <li>測試 piper 語音
                <pre><code>echo '這是測試' | \
piper --model piper_models/zh_CN-huayan-medium.onnx --output-raw | \
aplay -r 22050 -f S16_LE -t raw -</code></pre>
                如果可以聽到"這是測試"，就表示 pipe 可以正常工作
            </li>
        </ol>
        <h2>5. 安裝其他需要的 python 套件</h2>
        <ol>
            <li>安裝 sounddevice，用來撥放語音
                <pre><code>pip install sounddevice</code></pre>
            </li>
            <li>安裝 pyaudio，用來錄音
                <pre><code>pip install pyaudio</code></pre>
            </li>
            <li>安裝 Ollama 的 Python API，讓 Python 程式可以透過 ollama API與 Ollama 互動
                <pre><code>pip install ollama</code></pre>
            </li>
            <li>安裝 opencc，將簡體字轉成繁體字
                <pre><code>pip install opencc-python-reimplemented</code></pre>
            </li>
        </ol>
        <h2>6. python 語音聊天程式</h2>
        <p>由麥克風錄下使用者的聲音，經 Vosk 轉成 Text，再輸入大語言模型(LLM)，由 LLM 生成的文字，透過 Piper 轉成語音輸出</p>
        <pre><code>chat.py
import vosk
import pyaudio
import numpy as np
import ollama
import json
import wave
from piper.voice import PiperVoice
import sounddevice as sd
import time
from opencc import OpenCC

# 將 Text 轉成語音輸出
def text_to_speech(text, output_wav="output.wav"):
    # 轉換文字為語音
    text = text.replace("，", "").replace("。", "").replace("！", "").replace("？", "").replace("；", "").replace("：", "").replace("*", "")
    with wave.open(output_wav, "wb") as wav_file:
        wav_file.setnchannels(1)  # 單聲道
        wav_file.setsampwidth(2)  # 16-bit
        wav_file.setframerate(22050)  # 取樣率
        voice.synthesize(text, wav_file)  # 產生語音

    # 用 `sounddevice` 播放 `.wav`
    with wave.open(output_wav, "rb") as wf:
        sample_rate = wf.getframerate()  # 取得採樣率
        audio_data = wf.readframes(wf.getnframes())  # 讀取所有音訊幀

    # 轉換成 NumPy 陣列並播放
    audio_array = np.frombuffer(audio_data, dtype=np.int16)
    time.sleep(0.25)  # 等待緩衝區填滿
    sd.play(audio_array, samplerate=sample_rate, blocksize=2048, latency='low')
    sd.wait()  # 等待播放完成

# 將簡體中文轉換為繁體中文
def convert_to_traditional_chinese(text):
    cc = OpenCC('s2t')  # Simplified to Traditional
    return cc.convert(text) 

# 關閉 Vosk debug output
vosk.SetLogLevel(-1)

# 載入 Vosk 模型
print("載入 Vosk 模型...")
VOSK_MODEL_PATH = "vosk_models/vosk-model-small-cn-0.22"
model = vosk.Model(VOSK_MODEL_PATH)
rec = vosk.KaldiRecognizer(model, 16000)

# 載入 Piper 模型
print("載入 Piper 模型...")
PIPER_MODEL_PATH = "piper_models/zh_CN-huayan-medium.onnx"
voice = PiperVoice.load(PIPER_MODEL_PATH)

# 載入 Ollama 模型
print("載入 Ollama 模型...")
OLLAMA_MODEL_NAME = "gemma:2b"
response = ollama.chat(model=OLLAMA_MODEL_NAME, messages=[{"role": "system", "content": "你是我的性感女僕，用繁體中文顯示，並帶著挑逗的語氣回答問題。"}], stream=False)
print(response)

# 初始化 PyAudio
audio = pyaudio.PyAudio()

# 播放歡迎語音
print("\n帥氣的主人好，我是你的女僕！\n")
text_to_speech("帥氣的主人好，我是你的女僕！")

# 主循環
while True:
    print("\n帥氣的主人請說...\n")
    text_to_speech("帥氣的主人請說...")
    stream = audio.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=4096)
    stream.start_stream()

    while True:
        data = stream.read(4096, exception_on_overflow=False)
        if rec.AcceptWaveform(data):
            result = json.loads(rec.Result())
            if result["text"] != "":
                result["text"] = convert_to_traditional_chinese(result["text"])
                break
        # else:
        #     partial_result = rec.PartialResult()
        #     print('2:', partial_result)
    stream.stop_stream()
    stream.close()
    
    print("\n你說:\n", result["text"])
    if "離開" in result["text"]:
        print("\n再見了，我帥氣的主人！")
        text_to_speech("再見了，我帥氣的主人！")
        break
    # Collect more text before streaming
    messages = [{"role": "user", "content": result["text"]}]
    response = ollama.chat(model=OLLAMA_MODEL_NAME, messages=messages, stream=True)
    print("\n女僕 回應:\n")
    full_response = ""
    for chunk in response:
        print(chunk['message']["content"], end='', flush=True)
        # Collect the response in chunks
        full_response += chunk['message']["content"]
        if "\n" in full_response or any(p in full_response for p in "，。！？；："):
            text_to_speech(full_response.strip())
            full_response = ""
    if full_response:
        print('\n')
        text_to_speech(full_response.strip())</code></pre>
        <h2>7. 實機操作範例</h2>
        <p><a href="https://www.youtube.com/watch?v=qlKVKMWWvL4" target="_blank">https://www.youtube.com/watch?v=qlKVKMWWvL4</a></p>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/qlKVKMWWvL4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    </div>
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.5.4/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
</body>
</html>